# Breast-Cancer-Classification

Анализ данных и построение моделей машинного обучения для классификации опухолей молочной железы на злокачественные и доброкачественные. Проект включает в себя исследовательский анализ данных, инжиниринг признаков, сравнение и оптимизацию классификационных моделей, включая CatBoost, LightGBM, XGBoost, Random Forest и Logistic Regression.

# Анализ и прогнозирование рака молочной железы

## О проекте

Этот проект представляет собой исследование данных о раке молочной железы с целью выявления основных признаков, влияющих на классификацию опухолей, и построения предиктивной модели машинного обучения. Анализ выполнен на классическом наборе данных Wisconsin Breast Cancer Dataset, содержащем результаты тонкоигольной аспирационной биопсии.

Основная цель работы — разработать модель, способную с высокой точностью и, что критически важно, с минимальным количеством ложноотрицательных результатов классифицировать опухоли на злокачественные и доброкачественные на основе морфологических характеристик клеток.

## Структура проекта

*   `Анализ и прогнозирование рака груди.ipynb` — Jupyter Notebook, содержащий весь код для анализа данных, их предобработки, визуализации, построения и оценки моделей.

*   `data.csv` — исходный файл с данными Wisconsin Breast Cancer Dataset (необходимо разместить в корневой директории).

*   `requirements.txt` — список необходимых библиотек для воспроизведения окружения.

*   `README.md` — данный файл с описанием проекта.

## Этапы работы

1.  **Исследовательский анализ данных (EDA)**:

    *   Проведено изучение структуры и распределения данных. Выявлено, что данные не содержат пропусков (569 наблюдений по всем признакам), однако наблюдается сильный разброс масштабов признаков связанных с размером опухоли.

    *   С помощью корреляционного анализа и визуализаций распределений проанализировано влияние различных признаков на целевую переменную. Установлено, что признаки с припиской "worst" (наихудшие значения) имеют более высокую корреляцию с диагнозом, чем их аналоги "mean" и "se".

    *   Обнаружена высокая мультиколлинеарность между геометрическими признаками (radius, perimeter, area), что требует особого внимания при работе с линейными моделями.

    *   Применение PCA показало четкую линейную разделимость классов в двумерном пространстве, что указывает на возможность достижения высоких метрик даже линейными моделями.

2.  **Предобработка и инжиниринг признаков**:

    *   Созданы новые признаки для улучшения предсказательной силы модели:
        *   **Shape Factor** (`perimeter² / area`) — оценка неправильности формы опухоли, так как злокачественные опухоли имеют неровные края
        *   **Spread & Growth Ratio** — разница и отношение между worst и mean значениями, показывающие разброс характеристик
        *   **Concave Points Density** — нормированное количество вогнутых точек на длину периметра
        *   **Approx Volume** — аппроксимация объема клетки как трехмерного объекта

    *   Удалены неинформативные признаки с корреляцией менее 0.1 с целевой переменной (fractal_dimension_mean, texture_se, smoothness_se, symmetry_se, fractal_dimension_se).

    *   Устранена мультиколлинеарность путем удаления признаков с корреляцией более 0.95, при этом приоритет отдавался новым сгенерированным признакам, несущим более сложную нелинейную информацию.

    *   Итоговое количество признаков сократилось с 30 до 24, что улучшило качество модели и снизило риск переобучения.

3.  **Сравнение и выбор модели**:

    *   Проведено сравнение нескольких классификационных моделей: `Logistic Regression`, `Random Forest`, `XGBoost`, `LightGBM`, `CatBoost`.

    *   Все модели показали высокие результаты (Accuracy > 96%), однако лучшие метрики продемонстрировал `CatBoost`.

4.  **Оптимизация и финальная модель**:

    *   Для модели `CatBoost`, показавшей лучшие базовые метрики, был произведен подбор гиперпараметров с использованием `Optuna` с multi-objective оптимизацией.

    *   Оптимизация проводилась по двум целевым метрикам: **F1-Score** и **Recall**, с приоритетом на максимизацию Recall, так как ложноотрицательные результаты (пропуск злокачественной опухоли) критически недопустимы.

    *   Использована 5-fold стратифицированная кросс-валидация для оценки качества моделей. Построен Парето-фронт решений, из которого выбрана оптимальная модель с балансом между Recall и F1-Score.

    *   Оптимизация позволила достичь на отложенной тестовой выборке значения метрики **Recall = 100%** и **F1-Score = 100%**, что означает нулевое количество ложноотрицательных случаев.

## Как запустить проект

1.  **Клонируйте репозиторий:**

    ```bash
    git clone <URL-вашего-репозитория>
    cd <название-папки-репозитория>
    ```

2.  **Создайте виртуальное окружение и установите зависимости:**

    *   Убедитесь, что у вас установлен Python 3.x.

    *   Создайте и активируйте виртуальное окружение:

        ```bash
        python -m venv venv
        source venv/bin/activate  # Для Linux/macOS
        venv\Scripts\activate    # Для Windows
        ```

    *   Установите все необходимые библиотеки:

        ```bash
        pip install pandas numpy matplotlib seaborn scikit-learn xgboost lightgbm catboost optuna
        ```

        *Примечание: файл `requirements.txt` будет добавлен позже.*

3.  **Разместите данные:**

    *   Поместите файл с данными `data.csv` в корневую директорию проекта.

4.  **Запустите Jupyter Notebook:**

    ```bash
    jupyter notebook "Анализ и прогнозирование рака груди.ipynb"
    ```

## Результаты

Финальная модель `CatBoost` после оптимизации гиперпараметров показала следующие метрики на тестовом наборе данных:

*   **Accuracy**: 100.0%
*   **Precision**: 100.0%
*   **Recall**: 100.0% (критически важно для медицинской диагностики)
*   **F1-Score**: 100.0%
*   **ROC AUC**: 100.0%

Наиболее важными признаками для модели оказались:

1.  **Concave points worst** — количество вогнутых участков на контуре клетки (злокачественные клетки имеют рваные края)

2.  **Perimeter worst, Radius worst, Area worst** — геометрические размеры (злокачественные опухоли растут крупнее)

3.  **Concavity и Compactness** — форма и плотность клеток

4.  **Сгенерированные признаки** (Shape Factor, Spread Ratio) — улучшенные индикаторы злокачественности

### Сравнение базовых моделей

| Модель | Accuracy | F1-Score | ROC AUC |
|--------|----------|----------|---------|
| CatBoost | 97.37% | 96.30% | 100.0% |
| XGBoost | 97.37% | 96.30% | 99.93% |
| Random Forest | 97.37% | 96.30% | 99.64% |
| Logistic Regression | 97.37% | 96.39% | 99.60% |
| LightGBM | 96.49% | 95.00% | 99.87% |
